[
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Data Science & Analytics Blog\nWelcome to my blog where I share insights, tutorials, and thoughts about:\n\nHealthcare analytics and economics\nMachine learning applications\nSupply chain optimization\nData science best practices\nMLOps and production deployments\n\nFeel free to use the filters and sorting options to find posts that interest you. You can also browse by category using the tags below.\n\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nEconomic Analysis of Dynamic Pricing: From Theory to Reinforcement Learning\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2024\n\n\n13 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "photos.html",
    "href": "photos.html",
    "title": "Photo Gallery",
    "section": "",
    "text": "Data Science Conference 2023\n\n\n\n\n\n\n\nHealthcare Analytics Summit\n\n\n\n\n\n\n\nMLOps Workshop\n\n\n\n\n\n\n\n\n\n\n\n\nSupply Chain Optimization Model\n\n\nNetwork visualization of healthcare supply chain optimization\n\n\n\n\n\nPatient Flow Analysis\n\n\nHealthcare system patient flow analysis dashboard\n\n\n\n\n\n\n\n\n\n\nTeam Workshop\n\n\nData Science Team Workshop\n\n\n\n\n\nConference Panel\n\n\nHealthcare Analytics Panel Discussion\n\n\n\n\n\nResearch Presentation\n\n\nPresenting Research Findings\n\n\nNote: Photos are regularly updated to showcase recent work and events. Check back for new additions!"
  },
  {
    "objectID": "photos.html#conference-presentations-speaking-events",
    "href": "photos.html#conference-presentations-speaking-events",
    "title": "Photo Gallery",
    "section": "",
    "text": "Data Science Conference 2023\n\n\n\n\n\n\n\nHealthcare Analytics Summit\n\n\n\n\n\n\n\nMLOps Workshop"
  },
  {
    "objectID": "photos.html#project-visualizations",
    "href": "photos.html#project-visualizations",
    "title": "Photo Gallery",
    "section": "",
    "text": "Supply Chain Optimization Model\n\n\nNetwork visualization of healthcare supply chain optimization\n\n\n\n\n\nPatient Flow Analysis\n\n\nHealthcare system patient flow analysis dashboard"
  },
  {
    "objectID": "photos.html#recent-events",
    "href": "photos.html#recent-events",
    "title": "Photo Gallery",
    "section": "",
    "text": "Team Workshop\n\n\nData Science Team Workshop\n\n\n\n\n\nConference Panel\n\n\nHealthcare Analytics Panel Discussion\n\n\n\n\n\nResearch Presentation\n\n\nPresenting Research Findings\n\n\nNote: Photos are regularly updated to showcase recent work and events. Check back for new additions!"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links & Resources",
    "section": "",
    "text": "GitHub Repository\nLinkedIn Profile\nTwitter Feed\n\n\n\n\n\n\n\nHealthcare Analytics on Medium\nNEJM Catalyst\nHealth Affairs Blog\n\n\n\n\n\nPapers With Code\nTowards Data Science\nAnalytics Vidhya\n\n\n\n\n\nMLflow Documentation\nPytorch\nscikit-learn\n\n\n\n\n\n\nAMIA (American Medical Informatics Association)\nHIMSS (Healthcare Information and Management Systems Society)\nINFORMS (Institute for Operations Research and Management Sciences)\n\nNote: These are resources I find valuable in my work and research. Feel free to suggest additional resources!"
  },
  {
    "objectID": "links.html#publications-projects",
    "href": "links.html#publications-projects",
    "title": "Links & Resources",
    "section": "",
    "text": "GitHub Repository\nLinkedIn Profile\nTwitter Feed"
  },
  {
    "objectID": "links.html#recommended-reading",
    "href": "links.html#recommended-reading",
    "title": "Links & Resources",
    "section": "",
    "text": "Healthcare Analytics on Medium\nNEJM Catalyst\nHealth Affairs Blog\n\n\n\n\n\nPapers With Code\nTowards Data Science\nAnalytics Vidhya\n\n\n\n\n\nMLflow Documentation\nPytorch\nscikit-learn"
  },
  {
    "objectID": "links.html#professional-organizations",
    "href": "links.html#professional-organizations",
    "title": "Links & Resources",
    "section": "",
    "text": "AMIA (American Medical Informatics Association)\nHIMSS (Healthcare Information and Management Systems Society)\nINFORMS (Institute for Operations Research and Management Sciences)\n\nNote: These are resources I find valuable in my work and research. Feel free to suggest additional resources!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Hi there, I’m Cory! I’m a Lead Data Scientist specializing in healthcare analytics, economics, and machine learning. I’m particularly interested in industrial organization, probability, and reinforcement learning. I’ve spent my entire career working in the healthcare finance space, so that’s my primary area of expertise. This is mostly for exploring the other stuff :)"
  },
  {
    "objectID": "index.html#new-posts",
    "href": "index.html#new-posts",
    "title": "Welcome",
    "section": "New posts",
    "text": "New posts"
  },
  {
    "objectID": "blog/posts/dynamic-pricing.html",
    "href": "blog/posts/dynamic-pricing.html",
    "title": "Dynamic Pricing in a Very Dumb Vacuum",
    "section": "",
    "text": "Recent advancements in artificial intelligence, particularly reinforcement learning (RL), have been touted as potentially transformative for pricing strategies in oligopolistic markets. I don’t really buy it, but wasn’t super familiar with what the process here looked like in practice. In order to Get Familiar, I put together a simple model where firms compete on price, but with different pricing strategies. We’ll get to that later: first, some background."
  },
  {
    "objectID": "blog/posts/dynamic-pricing.html#introduction",
    "href": "blog/posts/dynamic-pricing.html#introduction",
    "title": "Dynamic Pricing in a Very Dumb Vacuum",
    "section": "",
    "text": "Recent advancements in artificial intelligence, particularly reinforcement learning (RL), have been touted as potentially transformative for pricing strategies in oligopolistic markets. I don’t really buy it, but wasn’t super familiar with what the process here looked like in practice. In order to Get Familiar, I put together a simple model where firms compete on price, but with different pricing strategies. We’ll get to that later: first, some background."
  },
  {
    "objectID": "blog/posts/dynamic-pricing.html#economic-foundations-of-pricing-strategy",
    "href": "blog/posts/dynamic-pricing.html#economic-foundations-of-pricing-strategy",
    "title": "Dynamic Pricing in a Very Dumb Vacuum",
    "section": "Economic Foundations of Pricing Strategy",
    "text": "Economic Foundations of Pricing Strategy\n\nTheoretical Underpinnings\nThe economic theory of pricing in oligopolistic markets has a rich history, dating back to the seminal works of (cournot1838?) and (bertrand1883?). These models laid the groundwork for understanding strategic interactions in imperfectly competitive markets. Subsequent developments, including the theory of contestable markets (Baumol, Panzar, and Willig 1982), have further refined our understanding of pricing dynamics and market entry.\nMost firms probably don’t set prices based on first order conditions. Acquiring all relevant data is costly, and it’s not totally possible to have perfect information about consumer responses to price changes in most environments (I can’t think of any where it would be possible). That said, optimal firm behavior in an ideal environment provides a nice benchmark for evaluating alternative price-setting approaches.\n\n\nAntitrust Considerations\nAntitrust policy has long been informed by economic theory. The structure-conduct-performance paradigm, proposed by Mason (1939) and developed by Bain (1968), has been influential in shaping antitrust thinking. Similarly, the Chicago School critique, articulated by scholars like Posner (1979), emphasizes the importance of efficiency considerations in antitrust analysis.\nIn practice, antitrust authorities have developed various tools to assess potentially anticompetitive pricing behaviors, including:\n\nPredatory Pricing Tests: The Areeda-Turner test (Areeda and Turner 1975) provides a cost-based framework for identifying predatory pricing.\nMarket Concentration Measures: Indices like the Herfindahl-Hirschman Index (HHI) are used to assess market concentration (U.S. Department of Justice and Federal Trade Commission 2010).\nUpward Pricing Pressure: In merger analysis, measures of upward pricing pressure help quantify incentives for post-merger price increases (Farrell and Shapiro 2010).\n\nThese tools are imperfect, much like the models they’re based on. HHI, for example, is particularly sensitive to industry definitions. Spatial competition and diversity of product offerings can skew the results HHI yields in a way that isn’t immediately obvious."
  },
  {
    "objectID": "blog/posts/dynamic-pricing.html#spectrum-of-pricing-approaches",
    "href": "blog/posts/dynamic-pricing.html#spectrum-of-pricing-approaches",
    "title": "Dynamic Pricing in a Very Dumb Vacuum",
    "section": "Spectrum of Pricing Approaches",
    "text": "Spectrum of Pricing Approaches\n\nFirst-Order Condition (FOC) Based Approaches\nThe traditional economic approach assumes firms set prices to maximize profits, usually defined something like:\n\\[\\pi_i(Q_{D,i}(p_i),p_i) = (p_i - c_i) \\cdot Q_d(p_i)\\]\nIf we assume firm \\(i\\)’s quantity demanded (\\(Q_{D_i}(p_i)\\)) is linear in price \\(p_i\\), and marginal costs \\(c_i\\) are fixed, we’ll have a profit function that looks something like:\n\\[\\pi_i(p_i) = (p_i - c_i) \\cdot (\\alpha - \\beta \\cdot p_i) \\]\nyielding familiar FOCs:\n\\[\\frac{\\partial \\pi_i}{\\partial p_i} = (\\alpha + \\beta c_i - 2 \\beta p_i)\\]\nand optimality condition\n\\[ p_i = \\frac{\\alpha + \\beta c_i}{2\\beta} \\]\nWe’re going to add a minor complicating factor here and assume that firms compete on prices, taking other firms’ behavior as given, as well as time-to-delivery, which is exogenously determined. In the long run I’d like to tweak this model so that time-to-delivery can be minimized via bilateral contracting with a third party company (this can be thought of as selling goods on Amazon), but for now we’re keeping it simple. This whole exercise was inspired by Amazon dropshippers, for what it’s worth.\nI’m mostly curious about how these firms will behave when competitors behave suboptimally. To that end, we’ll introduce two other firm types: one that follows a heuristic, and another that sets prices dynamically using reinforcement learning. All code for this exercise can be found here:.\n\n\nHeuristic Approaches\nIn practice, many firms rely on simpler heuristic methods for price setting. These “rules of thumb” are often easier to implement and communicate within an organization. Common heuristics include:\n\nCost-Plus Pricing: \\(p_i = c_i * (1 + \\varphi_i)\\), where \\(\\varphi_i\\) is a markup. In practice the markup is often based set on a combination of margin targets and projected demand.\nCompetitor-Based Pricing: \\(p_i = \\mathbb{E}\\[p_{-i}\\] * (1 + \\gamma_i)\\) - basically the firm takes the expected market price and adjusts it up or down by some percentage \\(\\gamma\\), again often based on some combination of a margin target and projected demand.\n\nHeuristic approaches can be surprisingly effective in complex, dynamic environments (Gigerenzer and Gaissmaier 2011). They often require less detailed information about demand or competitive conditions compared to FOC-based methods. While they may not lead to theoretically optimal profits, they can be “good enough” given the costs and complexities of implementing more sophisticated approaches (Simon 1956).\n\n\nReinforcement Learning Approaches\nReinforcement learning (RL) has been proposed as a new approach to pricing strategy. In an RL framework, pricing decisions are made by an agent that learns from the outcomes of its actions over time. The key components of an RL system for pricing typically include:\n\nState space: Market conditions, competitor prices, inventory levels, etc.\nAction space: Possible prices the firm can set\nReward function: Typically the profit earned from each pricing decision\n\nProponents argue that RL approaches have the potential to capture complex, non-linear relationships in the market without requiring explicit model specification, and can adapt to changing market conditions through continuous learning. They’re probably wrong at this point in time, but RL-based approaches are interesting nonetheless.\nWhy are they ‘probably wrong’?\n\nAdaptability: Firms using FOC or heuristic approaches can and do update their strategies based on market outcomes.\nComplexity: While RL can handle complex state spaces, it’s not clear that this additional complexity leads to better outcomes in many real-world pricing scenarios.\nLearning: Traditional approaches also “learn” from data, albeit in a more structured manner.\n\nMoreover, RL strategies might essentially learn to emulate existing heuristic approaches:\n\nCompetitor-Based Pricing: An RL agent might learn to price relative to competitors - and those competitors may in turn be RL agents!\nValue-Based Pricing: Through interactions with the market, an RL agent could learn to estimate customers’ willingness to pay and price accordingly.\n\nIn this light, RL might be viewed not as a revolutionary new approach, but as a potentially more “efficient” way of implementing and combining existing pricing strategies. “Efficient” is in scare quotes because deviations from optimal behavior generate deadweight loss by definition, as well as the fact that deploying AI models at scale in the year 2024 generates non-negligible externalities."
  },
  {
    "objectID": "blog/posts/dynamic-pricing.html#comparative-analysis-and-simulation-setup",
    "href": "blog/posts/dynamic-pricing.html#comparative-analysis-and-simulation-setup",
    "title": "Dynamic Pricing in a Very Dumb Vacuum",
    "section": "Comparative Analysis and Simulation Setup",
    "text": "Comparative Analysis and Simulation Setup\nLet’s outline the model we’ll use in the simulation here.\n\nMarket Model: The general version of the model we’re looking at here has N firms employing one of three strategies:\n\nFOC-based: Given known demand and a simple production function, firms maximize profits based on first order conditions\nHeuristic: Firms use competitor-based pricing with periodic adjustments\nRL-based: Firms use a Deep Q-Network to learn pricing strategies\n\n\nand facing demand:\n\\[D_i = \\alpha - \\beta p_i + \\gamma \\sum_{j\\neq i} p_j - \\rho d_i + \\xi \\sum_{j\\neq i} d_j\\]\nwhere \\(p_i\\) is firm i’s price, \\(d_i\\) is its delivery time (exogenously determined), and \\(\\alpha, \\beta, \\xi, \\rho\\) are parameters.\n\nSimulation Dynamics: The simulation will run for T periods, with firms making pricing decisions in each period based on their respective strategies. We’re going to keep it simple and have one firm of each type, but two FOC firms (really just as a sanity check to make sure everyone’s behavior is as expected - the two FOC firms should behave very similarly)\nOutcome Measures: We will track prices, profits, and market concentration over time.\n\nAll of the code for the simulation below can be found in this repo.\n\nfrom dynamic_pricing_sim import Market, FOCFirm, HeuristicFirm, RLFirm, run_simulation, plot_results\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Set up the market\ndemand_params = {\n    'alpha': 100,\n    'beta': 20,\n    'gamma': 6,\n    'xi': 0,\n    'rho': 0\n}\nmarket = Market(4,demand_params)\n\nfoc_firm = FOCFirm.FOCFirm(cost=5, market=market)\nheuristic_firm = HeuristicFirm.HeuristicFirm(cost=5, markup=0.1)\nfoc_firm_2 = FOCFirm.FOCFirm(cost=5, market=market)\nrl_hyperparams = RLFirm.RLHyperParams\nrl_hyperparams.epsilon = 0.5\nrl_firm = RLFirm.RLFirm(state_size=9, action_size=40, cost=5)\n\n\n# Set up the firms\nfirms = [\n    foc_firm,\n    foc_firm_2,\n    heuristic_firm,\n    rl_firm\n]\n\n\n\n# Set delivery times (assumed constant for simplicity)\ndelivery_times = np.array([1, 1, 1, 1])\n\n# Run the simulation\nT = 1000  \nprices_history, profits_history, demand_history = run_simulation(T, market, firms, delivery_times)\n\n# Plot the results\nfig = plot_results(prices_history, profits_history, demand_history,['FOC', 'FOC2', 'Heuristic', 'RL'])\nplt.show()\n\nC:\\Users\\Cory\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\dynamic_pricing_sim\\equilibrium.py:15: RuntimeWarning: The iteration is not making good progress, as measured by the \n  improvement from the last ten iterations.\n  equilibrium_prices = fsolve(equations, initial_guess)\n\n\nRecent avg profit: -40.09, Last price: 9.53, Last profit: -2.36\nRecent avg profit: -13.68, Last price: 9.53, Last profit: -45.29\nRecent avg profit: 10.65, Last price: 6.56, Last profit: 0.00\nRecent avg profit: 49.78, Last price: 7.15, Last profit: 16.86\nRecent avg profit: 76.49, Last price: 9.88, Last profit: 116.33\nRecent avg profit: 84.36, Last price: 9.88, Last profit: 116.33\nRecent avg profit: 100.92, Last price: 9.88, Last profit: 116.33\nRecent avg profit: 107.18, Last price: 9.88, Last profit: 116.33\nRecent avg profit: 113.08, Last price: 9.88, Last profit: 116.33\nRecent avg profit: 113.05, Last price: 9.88, Last profit: 116.33\n\n\n\n\n\n\n\n\n\nOk so the RL firm settles into a decent strategy over time that behaves reasonably well in the long-run. The FOC firms are mostly stable, as expected, and the heuristic firm is all over the place. That’s what you get for raising prices erratically for no reason! Bad profits!\nHere are some of the summary stats we get from the above:\n\navg_prices = np.mean(prices_history, axis=0)\navg_profits = np.mean(profits_history, axis=0)\nprice_volatility = np.std(prices_history, axis=0)\n\nprint(\"Average Prices:\")\nfor i, firm_type in enumerate(['FOC', 'FOC2', 'Heuristic', 'RL']):\n    print(f\"{firm_type} Firm: {avg_prices[i]:.2f}\")\n\nprint(\"\\nAverage Profits:\")\nfor i, firm_type in enumerate(['FOC', 'FOC2', 'Heuristic', 'RL']):\n    print(f\"{firm_type} Firm: {avg_profits[i]:.2f}\")\n\nAverage Prices:\nFOC Firm: 9.60\nFOC2 Firm: 9.57\nHeuristic Firm: 17.74\nRL Firm: 7.30\n\nAverage Profits:\nFOC Firm: 75.39\nFOC2 Firm: 75.28\nHeuristic Firm: -0.00\nRL Firm: 60.17"
  },
  {
    "objectID": "blog/posts/dynamic-pricing.html#critical-evaluation-and-antitrust-implications",
    "href": "blog/posts/dynamic-pricing.html#critical-evaluation-and-antitrust-implications",
    "title": "Dynamic Pricing in a Very Dumb Vacuum",
    "section": "Critical Evaluation and Antitrust Implications",
    "text": "Critical Evaluation and Antitrust Implications\nThis simulation setup allows us to critically evaluate several key questions:\n\nHow do RL-based pricing strategies perform compared to traditional FOC-based and heuristic approaches in terms of firm profitability and market outcomes?\n\n\nObviously the firm that is literally optimizing/maximizing profit wins - the rules of the game here are skewed. That said, the RL firm significantly outperforms our (admittedly dumb) heuristic in this simple model\n\n\nDo RL strategies converge to known optimal strategies in simple market settings? If so, do they offer any advantage over traditional methods?\n\n\nIt’s obvious that this simple RL agent does not learn the optimal pricing strategy. It’s also a bit of a pain in the neck to calibrate - it took me a decent amount of time to get to a point where the model would get consistently reasonable results - I ended up having to drop the delivery times from demand, at least for this run, to get the RL agent to deliver non-negative profits. A decent amount of reward shaping was also required.\n\n\nIn more complex settings, do RL strategies discover genuinely novel pricing strategies, or do they essentially learn to implement sophisticated versions of known heuristics?\n\n\nThis project took me a few hours of work to get up and running, and frankly at the end of it I’m not totally sure what strategy the agent settled on. My hunch is that it gets stuck in a local optimum - there were scenarios where it appeared to be maximizing quantity demanded as opposed to profit, but the relative simplicity of the model and limited training time makes me think that it was just converging to a local optimum.\n\n\nHow does the presence of RL-based pricing affect market dynamics and the behavior of firms using other pricing strategies?\n\n\nThe FOC firms aren’t really impacted by the RL firm - given non-zero price response by design, the FOC firm does exhibit some (very small) price volatility, but ultimately the consistency is well on display. Heuristic firms, however, become fairly erratic. I think this is probably a reasonable approximation of reality - firms with a well-established pricing strategy based on knowledge of their consumers and internal operation are going to know how to respond to competitors’ erratic behavior, whereas firms who are pricing based solely on perceptions of market conditions are going to struggle a bit more. In reality, the RL firm would likely train on historical firm data as well as publicly available price histories, so the ‘exploration’ periods would likely happen ‘in the lab’. That said, in practice dynamic pricing models are much more intricate than the one presented here, and in turn much more opaque - and less predictable in the face of shocks.\n\n\nWhat are the computational and data requirements for implementing RL-based pricing, and how do these compare to the requirements for sophisticated implementations of traditional approaches?\n\n\nSo if you’re putting together a silly lil model on your personal laptop, this simulation runs start-to-finish in about 5 seconds. And compared to some of the other work I’ve done in the pricing space, it was a pain in the neck to set up and calibrate. As nice as it would be to get something like this set up right and let it try to solve my own \\(\\pi-max\\) problems, I’m reminded of the adage that’s been circulating a lot with the rise of the LLM: \n\nUltimately theese things need a ton of guardrails to avoid erratic behavior, and these guardrails ultimately serve to simulate the optimal behavior we’re trying to avoid modeling in the first place. There are a bunch of other non-theoretical reasons, like customer retention or avoidance of tacit collusive behavior, that we might not want to outsource this work too. So like, maybe we should just do the work. I can think of a dozen real-world use cases of RL in an operations management setting, but price setting doesn’t seem like a great candidate.\nOn the topic of tacit collusion, from an antitrust perspective it’s super important to understand whether RL algorithms fundamentally change the nature of market competition. Can RL algorithms learn to coordinate on high markups without explicit collusion? If so, is this fundamentally different from tacit collusion that can arise with traditional pricing methods? The former seems likely, especially if you have two agents functionally following the same strategy by being trained with the same data. There’s an interesting segment on quant work from Good News that talks a bit about how the algorithms quants use at finance firms\n{{https://youtu.be/DuBrreMiZlA?si=F83ljDsEuN-AE-5J}}\nin particular\n\nSo if you’re … yapping about this wacky new trading strategy you found, they’re going to go implement it at their firm and you’re gonna lose all your edge\n\nThere are fundamentally two types of model variation here: features incorporated and model architecture. My gut says that in most of the ways that matter, these two should converge in the long run - if one model outperforms another, competitors will work to identify where the advantage is coming from and adopt it. It’s somewhere between efficient markets and no-free lunch: in the long-run, the models are the same. Once we’ve extracted all the juice from dynamic pricing we’re left where we started, good old cost minimization.\nFirms considering implementing these strategies are likely not cost-constrained, but the cost of training and serving these models is non-negligible and should probably incorporated into the broader ROI calc when it comes to incorporating these as an alternative to more traditional price-setting strategies.\nMost of what I’ve learned in this exercise was basically how to go about setting up a dynamic pricing agent, as most of my background in RL previously was thinking about how roombas should work or trying to figure out why a Q-learning agent I birthed sucks so bad at jumping over the green pipe that’s just a little too tall.\nWas it otherwise valuable? My take is that there are basically three conditions you need to meet for this to be worth thinking about:\n1. Your firm is already on a cloud services provider that makes deployment at scale easy\n2. That cloud environment also has well-constructed feature store that'd make these model builds easier\n3. You have a ton of time on your hands and have already worked through the stuff that you *know* is going to add value\nIf you can check all three boxes here, this is probably a great exercise - especially if you’re able to incorporate sentiment analysis into the pipeline. There are very few industries where attaining FOC outcomes are realistic, and it’s totally plausible that well-designed RL-based pricing could mark an improvement over existing workflows, particularly if your pricing/strategy teams are using bad heuristics (like taking a fixed markup percentage over competitor prices). These things are a bit opaque though, and in practice I will likely stick toward more interpretable models that incorporate what all parties can agree are the relevant structural features."
  },
  {
    "objectID": "blog/posts/dynamic-pricing.html#conclusion",
    "href": "blog/posts/dynamic-pricing.html#conclusion",
    "title": "Economic Analysis of Dynamic Pricing: From Theory to Reinforcement Learning",
    "section": "Conclusion",
    "text": "Conclusion"
  },
  {
    "objectID": "index.html#new-posts-1",
    "href": "index.html#new-posts-1",
    "title": "Welcome",
    "section": "New posts",
    "text": "New posts"
  }
]